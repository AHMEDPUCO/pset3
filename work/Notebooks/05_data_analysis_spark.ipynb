{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e42e32",
   "metadata": {},
   "source": [
    "\n",
    "# Notebook 05: Preguntas de Negocio usando Spark\n",
    "\n",
    "**Objetivo:** Responder 20 preguntas de negocio usando `ANALYTICS.OBT_TRIPS` con Spark optimizado.\n",
    "\n",
    "**Optimizaciones implementadas:**\n",
    "1. Caché estratégico del DataFrame base\n",
    "2. Reparticionado óptimo para agregaciones\n",
    "3. Liberación de memoria entre queries\n",
    "4. Uso de *approx percentiles* para grandes volúmenes\n",
    "5. Persist solo cuando es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21372b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Snowflake context activo: DB=SPARK_DATA, SCHEMA=SPARK_DATA.RAW, WH=spark_wh, ROLE=ACCOUNTADMIN\n",
      "✓ Spark configurado con optimizaciones\n",
      "  Database:  SPARK_DATA\n",
      "  Schema:    ANALYTICS\n",
      "  RUN_ID:    20251020_005708\n",
      "  Evidencias: /home/jovyan/work/evidencias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.snowflake_utils import get_spark_session, get_snowflake_options\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import os, pathlib, gc\n",
    "from datetime import datetime\n",
    "\n",
    "spark = get_spark_session(\"preguntas_negocio_obt\")\n",
    "\n",
    "# Optimizaciones de configuración\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "\n",
    "sf_options_analytics = get_snowflake_options(schema=\"ANALYTICS\")\n",
    "db = sf_options_analytics[\"sfDatabase\"]\n",
    "schema_analytics = sf_options_analytics[\"sfSchema\"]\n",
    "\n",
    "EVID_DIR = os.environ.get(\"EVID_DIR\", \"/home/jovyan/work/evidencias\")\n",
    "pathlib.Path(EVID_DIR).mkdir(parents=True, exist_ok=True)\n",
    "RUN_ID = os.environ.get(\"RUN_ID\", datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "print(\"✓ Spark configurado con optimizaciones\")\n",
    "print(f\"  Database:  {db}\")\n",
    "print(f\"  Schema:    {schema_analytics}\")\n",
    "print(f\"  RUN_ID:    {RUN_ID}\")\n",
    "print(f\"  Evidencias: {EVID_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833313cb-dd15-4839-955d-c5cdf35aef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeouts/heartbeat para conexiones lentas/red con latencia\n",
    "spark.conf.set(\"spark.sql.broadcastTimeout\", \"600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc2668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_result(df, filename, description, show_rows=20):\n",
    "    \"\"\"Guarda resultado, muestra preview y libera memoria.\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Pregunta: {description}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        df.show(show_rows, truncate=False)\n",
    "\n",
    "        # Guardar CSV pequeño (agregados con límites)\n",
    "        pdf = df.toPandas()\n",
    "        filepath = f\"{EVID_DIR}/{filename}\"\n",
    "        pdf.to_csv(filepath, index=False)\n",
    "        print(f\"✓ Guardado: {filepath}\")\n",
    "        del pdf\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error en {description}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce520a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Años detectados: [2098, 2070, 2053, 2041, 2029, 2028, 2022, 2021, 2020, 2018, 2017, 2016, 2015, 2012, 2011, 2010, 2009, 2008, 2004, 2003, 2002, 2001]\n",
      "Cargando year=2098 ...\n",
      "Cargando year=2070 ...\n",
      "Cargando year=2053 ...\n",
      "Cargando year=2041 ...\n",
      "Cargando year=2029 ...\n",
      "Cargando year=2028 ...\n",
      "Cargando year=2022 ...\n",
      "Cargando year=2021 ...\n",
      "Cargando year=2020 ...\n",
      "Cargando year=2018 ...\n",
      "Cargando year=2017 ...\n",
      "Cargando year=2016 ...\n",
      "Cargando year=2015 ...\n",
      "Cargando year=2012 ...\n",
      "Cargando year=2011 ...\n",
      "Cargando year=2010 ...\n",
      "Cargando year=2009 ...\n",
      "Cargando year=2008 ...\n",
      "Cargando year=2004 ...\n",
      "Cargando year=2003 ...\n",
      "Cargando year=2002 ...\n",
      "Cargando year=2001 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o1083.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 3) Persistencia segura y gatillo mínimo (sin count, sin foreach RDD)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpersist(StorageLevel\u001b[38;5;241m.\u001b[39mMEMORY_AND_DISK)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ DataFrame cargado y persistido\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m df\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o1083.showString"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel\n",
    "import os\n",
    "\n",
    "db = sf_options_analytics[\"sfDatabase\"]\n",
    "schema_analytics = sf_options_analytics[\"sfSchema\"]\n",
    "OBT_TABLE = os.environ.get(\"OBT_TABLE\", \"OBT_TRIPS\")\n",
    "\n",
    "columns = [\n",
    "    \"service_type\", \"pickup_datetime\", \"dropoff_datetime\",\n",
    "    \"pickup_date\", \"pickup_hour\", \"day_of_week\", \"month\", \"year\",\n",
    "    \"pu_location_id\", \"pu_zone\", \"pu_borough\",\n",
    "    \"do_location_id\", \"do_zone\", \"do_borough\",\n",
    "    \"vendor_id\", \"vendor_name\",\n",
    "    \"rate_code_id\", \"rate_code_desc\",\n",
    "    \"payment_type\", \"payment_type_desc\",\n",
    "    \"trip_type\", \"passenger_count\", \"trip_distance\",\n",
    "    \"fare_amount\", \"tip_amount\", \"tip_pct\",\n",
    "    \"tolls_amount\", \"congestion_surcharge\",\n",
    "    \"total_amount\", \"trip_duration_min\", \"avg_speed_mph\"\n",
    "]\n",
    "\n",
    "# 1) Descubre años disponibles con un query pequeño\n",
    "years_df = (spark.read.format(\"net.snowflake.spark.snowflake\")\n",
    "            .options(**sf_options_analytics)\n",
    "            .option(\"query\", f\"SELECT DISTINCT year FROM {db}.{schema_analytics}.{OBT_TABLE} ORDER BY year DESC\")\n",
    "            .load())\n",
    "\n",
    "years = [int(r[\"YEAR\"]) for r in years_df.collect()]\n",
    "print(\"Años detectados:\", years)\n",
    "\n",
    "# 2) Lee por partición (año) y une, evitando materializar todo de golpe\n",
    "dfs = []\n",
    "for y in years:\n",
    "    print(f\"Cargando year={y} ...\")\n",
    "    part = (spark.read.format(\"net.snowflake.spark.snowflake\")\n",
    "            .options(**sf_options_analytics)\n",
    "            .option(\"query\", f\"SELECT {', '.join(columns)} FROM {db}.{schema_analytics}.{OBT_TABLE} WHERE year={y}\")\n",
    "            .load())\n",
    "    dfs.append(part.select(*columns))\n",
    "\n",
    "assert dfs, \"No se cargaron particiones.\"\n",
    "\n",
    "df = dfs[0]\n",
    "for p in dfs[1:]:\n",
    "    df = df.unionByName(p, allowMissingColumns=True)\n",
    "\n",
    "# 3) Persistencia segura y gatillo mínimo (sin count, sin foreach RDD)\n",
    "df = df.repartition(64, \"year\", \"month\").persist(StorageLevel.MEMORY_AND_DISK)\n",
    "df.select(\"year\").groupBy().agg(F.count(\"*\").alias(\"rows\")).show(1)\n",
    "print(\"✓ DataFrame cargado y persistido\")\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00362d56",
   "metadata": {},
   "source": [
    "\n",
    "## Preguntas de Negocio (20 según PDF)\n",
    "\n",
    "Todas usando Spark con optimizaciones de memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d3a39",
   "metadata": {},
   "source": [
    "### a) Top 10 zonas de pickup por volumen mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d85d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa = (\n",
    "    df.groupBy(\"year\", \"month\", \"pu_zone\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"trips\")\n",
    "    .orderBy(F.desc(\"year\"), F.desc(\"month\"), F.desc(\"trips\"))\n",
    "    .limit(120)\n",
    ")\n",
    "save_result(qa, \"a_top_pu_zones_monthly.csv\", \"Top 10 zonas de pickup por volumen mensual\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e64bc",
   "metadata": {},
   "source": [
    "### b) Top 10 zonas de dropoff por volumen mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qb = (\n",
    "    df.groupBy(\"year\", \"month\", \"do_zone\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"trips\")\n",
    "    .orderBy(F.desc(\"year\"), F.desc(\"month\"), F.desc(\"trips\"))\n",
    "    .limit(120)\n",
    ")\n",
    "save_result(qb, \"b_top_do_zones_monthly.csv\", \"Top 10 zonas de dropoff por volumen mensual\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f9109",
   "metadata": {},
   "source": [
    "### c) Evolución mensual de total_amount y tip_pct por borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qc = (\n",
    "    df.filter(F.col(\"pu_borough\") != \"Unknown\")\n",
    "    .groupBy(\"year\", \"month\", \"pu_borough\")\n",
    "    .agg(\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_total_amount\"),\n",
    "        F.round(F.avg(\"tip_pct\"), 2).alias(\"avg_tip_pct\"),\n",
    "        F.count(\"*\").alias(\"trips\")\n",
    "    )\n",
    "    .orderBy(\"year\", \"month\", \"pu_borough\")\n",
    ")\n",
    "save_result(qc, \"c_monthly_evolution_by_borough.csv\", \"Evolución mensual por borough\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fa5cb",
   "metadata": {},
   "source": [
    "### d) Ticket promedio por service_type y mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qd = (\n",
    "    df.groupBy(\"year\", \"month\", \"service_type\")\n",
    "    .agg(\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_ticket\"),\n",
    "        F.count(\"*\").alias(\"trips\")\n",
    "    )\n",
    "    .orderBy(\"year\", \"month\", \"service_type\")\n",
    ")\n",
    "save_result(qd, \"d_avg_ticket_by_service_month.csv\", \"Ticket promedio por servicio y mes\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525c588",
   "metadata": {},
   "source": [
    "### e) Viajes por hora del día y día de semana (picos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55331570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qe = (\n",
    "    df.groupBy(\"pickup_hour\", \"day_of_week\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"trips\")\n",
    "    .orderBy(F.desc(\"trips\"))\n",
    "    .limit(100)\n",
    ")\n",
    "save_result(qe, \"e_trips_by_hour_dow.csv\", \"Viajes por hora y día de semana (picos)\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0586b6",
   "metadata": {},
   "source": [
    "### f) p50/p90 de trip_duration_min por borough de pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qf = (\n",
    "    df.filter((F.col(\"pu_borough\") != \"Unknown\") & (F.col(\"trip_duration_min\") > 0))\n",
    "    .groupBy(\"pu_borough\")\n",
    "    .agg(\n",
    "        F.round(F.expr(\"percentile_approx(trip_duration_min, 0.5)\"), 2).alias(\"p50_duration\"),\n",
    "        F.round(F.expr(\"percentile_approx(trip_duration_min, 0.9)\"), 2).alias(\"p90_duration\"),\n",
    "        F.count(\"*\").alias(\"trips\")\n",
    "    )\n",
    "    .orderBy(\"pu_borough\")\n",
    ")\n",
    "save_result(qf, \"f_duration_percentiles_by_borough.csv\", \"Percentiles de duración por borough\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b4c295",
   "metadata": {},
   "source": [
    "### g) avg_speed_mph por franja horaria y borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qg = (\n",
    "    df.filter(\n",
    "        (F.col(\"pu_borough\") != \"Unknown\") & \n",
    "        (F.col(\"avg_speed_mph\").isNotNull()) & \n",
    "        (F.col(\"avg_speed_mph\") > 0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"time_slot\",\n",
    "        F.when(F.col(\"pickup_hour\").between(6, 9), \"06-09 Morning\")\n",
    "         .when(F.col(\"pickup_hour\").between(17, 20), \"17-20 Evening\")\n",
    "         .otherwise(\"Other\")\n",
    "    )\n",
    "    .groupBy(\"time_slot\", \"pu_borough\")\n",
    "    .agg(\n",
    "        F.round(F.avg(\"avg_speed_mph\"), 2).alias(\"avg_speed\"),\n",
    "        F.count(\"*\").alias(\"trips\")\n",
    "    )\n",
    "    .orderBy(\"time_slot\", \"pu_borough\")\n",
    ")\n",
    "save_result(qg, \"g_avg_speed_by_timeslot_borough.csv\", \"Velocidad promedio por franja y borough\", 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0a412",
   "metadata": {},
   "source": [
    "### h) Participación por payment_type_desc y relación con tip_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0142513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_trips = df.count()\n",
    "qh = (\n",
    "    df.groupBy(\"payment_type_desc\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"tip_pct\"), 2).alias(\"avg_tip_pct\"),\n",
    "        F.round(F.avg(\"tip_amount\"), 2).alias(\"avg_tip_amount\")\n",
    "    )\n",
    "    .withColumn(\"pct_of_total\", F.round(F.col(\"trips\") * 100.0 / F.lit(total_trips), 2))\n",
    "    .orderBy(F.desc(\"trips\"))\n",
    ")\n",
    "save_result(qh, \"h_payment_type_participation.csv\", \"Participación por tipo de pago\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f76e2b",
   "metadata": {},
   "source": [
    "### i) Rate codes con mayor trip_distance y total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qi = (\n",
    "    df.groupBy(\"rate_code_desc\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.sum(\"trip_distance\"), 2).alias(\"total_distance\"),\n",
    "        F.round(F.avg(\"trip_distance\"), 2).alias(\"avg_distance\"),\n",
    "        F.round(F.sum(\"total_amount\"), 2).alias(\"total_revenue\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_amount\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"total_distance\"))\n",
    ")\n",
    "save_result(qi, \"i_rate_codes_distance_revenue.csv\", \"Rate codes por distancia y revenue\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc7235",
   "metadata": {},
   "source": [
    "### j) Mix yellow vs green por mes y borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qj = (\n",
    "    df.filter(F.col(\"pu_borough\") != \"Unknown\")\n",
    "    .groupBy(\"year\", \"month\", \"pu_borough\", \"service_type\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"trips\")\n",
    "    .orderBy(F.desc(\"year\"), F.desc(\"month\"), \"pu_borough\", \"service_type\")\n",
    "    .limit(200)\n",
    ")\n",
    "save_result(qj, \"j_service_mix_by_month_borough.csv\", \"Mix yellow vs green por mes y borough\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b91f6b",
   "metadata": {},
   "source": [
    "### k) Top 20 flujos PU→DO por volumen y ticket promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qk = (\n",
    "    df.filter((F.col(\"pu_zone\") != \"Unknown\") & (F.col(\"do_zone\") != \"Unknown\"))\n",
    "    .groupBy(\"pu_zone\", \"do_zone\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_ticket\"),\n",
    "        F.round(F.sum(\"total_amount\"), 2).alias(\"total_revenue\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"trips\"))\n",
    "    .limit(20)\n",
    ")\n",
    "save_result(qk, \"k_top_routes_volume.csv\", \"Top 20 flujos PU→DO\", 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004ea2e",
   "metadata": {},
   "source": [
    "### l) Distribución de passenger_count y efecto en total_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f380897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ql = (\n",
    "    df.filter(F.col(\"passenger_count\").between(1, 9))\n",
    "    .groupBy(\"passenger_count\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_total_amount\"),\n",
    "        F.round(F.avg(\"trip_distance\"), 2).alias(\"avg_distance\")\n",
    "    )\n",
    "    .orderBy(\"passenger_count\")\n",
    ")\n",
    "save_result(ql, \"l_passenger_count_distribution.csv\", \"Distribución passenger_count\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea814efc",
   "metadata": {},
   "source": [
    "### m) Impacto de tolls_amount y congestion_surcharge por zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46877d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qm = (\n",
    "    df.filter(F.col(\"pu_zone\") != \"Unknown\")\n",
    "    .groupBy(\"pu_zone\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"tolls_amount\"), 2).alias(\"avg_tolls\"),\n",
    "        F.round(F.avg(\"congestion_surcharge\"), 2).alias(\"avg_congestion\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_total\")\n",
    "    )\n",
    "    .filter(F.col(\"trips\") >= 1000)\n",
    "    .orderBy(F.desc(\"avg_tolls\"))\n",
    "    .limit(30)\n",
    ")\n",
    "save_result(qm, \"m_surcharges_impact_by_zone.csv\", \"Impacto de tolls y congestion por zona\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a07758",
   "metadata": {},
   "source": [
    "### n) Proporción viajes cortos vs largos por borough y estacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378cd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qn = (\n",
    "    df.filter(F.col(\"pu_borough\") != \"Unknown\")\n",
    "    .withColumn(\n",
    "        \"trip_category\",\n",
    "        F.when(F.col(\"trip_distance\") <= 2, \"Short (<=2mi)\")\n",
    "         .when(F.col(\"trip_distance\") <= 5, \"Medium (2-5mi)\")\n",
    "         .otherwise(\"Long (>5mi)\")\n",
    "    )\n",
    "    .groupBy(\"pu_borough\", \"month\", \"trip_category\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"trips\")\n",
    "    .orderBy(\"pu_borough\", \"month\", \"trip_category\")\n",
    "    .limit(300)\n",
    ")\n",
    "save_result(qn, \"n_trip_length_distribution.csv\", \"Proporción viajes cortos vs largos\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce9515",
   "metadata": {},
   "source": [
    "### o) Diferencias por vendor en avg_speed_mph y trip_duration_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qo = (\n",
    "    df.filter((F.col(\"avg_speed_mph\").isNotNull()) & (F.col(\"avg_speed_mph\") > 0))\n",
    "    .groupBy(\"vendor_name\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"avg_speed_mph\"), 2).alias(\"avg_speed\"),\n",
    "        F.round(F.avg(\"trip_duration_min\"), 2).alias(\"avg_duration\"),\n",
    "        F.round(F.avg(\"trip_distance\"), 2).alias(\"avg_distance\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"trips\"))\n",
    ")\n",
    "save_result(qo, \"o_vendor_performance.csv\", \"Diferencias por vendor\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6060a",
   "metadata": {},
   "source": [
    "### p) Relación método de pago ↔ tip_amount por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qp = (\n",
    "    df.groupBy(\"pickup_hour\", \"payment_type_desc\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"tip_amount\"), 2).alias(\"avg_tip\"),\n",
    "        F.round(F.avg(\"tip_pct\"), 2).alias(\"avg_tip_pct\")\n",
    "    )\n",
    "    .orderBy(\"pickup_hour\", F.desc(\"trips\"))\n",
    "    .limit(200)\n",
    ")\n",
    "save_result(qp, \"p_payment_tip_by_hour.csv\", \"Método de pago y propina por hora\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e79e3",
   "metadata": {},
   "source": [
    "### q) Zonas con percentil 99 de duración/distancia fuera de rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qq = (\n",
    "    df.filter(F.col(\"pu_zone\") != \"Unknown\")\n",
    "    .groupBy(\"pu_zone\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.expr(\"percentile_approx(trip_duration_min, 0.99)\"), 2).alias(\"p99_duration\"),\n",
    "        F.round(F.expr(\"percentile_approx(trip_distance, 0.99)\"), 2).alias(\"p99_distance\")\n",
    "    )\n",
    "    .filter(F.col(\"trips\") >= 1000)\n",
    "    .orderBy(F.desc(\"p99_duration\"))\n",
    "    .limit(30)\n",
    ")\n",
    "save_result(qq, \"q_zones_extreme_p99.csv\", \"Zonas con p99 extremo (congestión potencial)\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417f129",
   "metadata": {},
   "source": [
    "### r) Yield por milla (total_amount/trip_distance) por borough y hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01afefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qr = (\n",
    "    df.filter((F.col(\"pu_borough\") != \"Unknown\") & (F.col(\"trip_distance\") > 0))\n",
    "    .groupBy(\"pu_borough\", \"pickup_hour\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(F.col(\"total_amount\") / F.col(\"trip_distance\")), 2).alias(\"yield_per_mile\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_amount\"),\n",
    "        F.round(F.avg(\"trip_distance\"), 2).alias(\"avg_distance\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"yield_per_mile\"))\n",
    "    .limit(100)\n",
    ")\n",
    "save_result(qr, \"r_yield_per_mile.csv\", \"Yield por milla por borough y hora\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c480e",
   "metadata": {},
   "source": [
    "### s) Cambios YoY en volumen y ticket promedio por service_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yearly = (\n",
    "    df.groupBy(\"year\", \"service_type\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trips\"),\n",
    "        F.round(F.avg(\"total_amount\"), 2).alias(\"avg_ticket\")\n",
    "    )\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"service_type\").orderBy(\"year\")\n",
    "qs = (\n",
    "    yearly\n",
    "    .withColumn(\"prev_year_trips\", F.lag(\"trips\").over(w))\n",
    "    .withColumn(\"prev_year_ticket\", F.lag(\"avg_ticket\").over(w))\n",
    "    .withColumn(\"yoy_trips_pct\", F.round((F.col(\"trips\") - F.col(\"prev_year_trips\")) * 100.0 / F.col(\"prev_year_trips\"), 2))\n",
    "    .withColumn(\"yoy_ticket_pct\", F.round((F.col(\"avg_ticket\") - F.col(\"prev_year_ticket\")) * 100.0 / F.col(\"prev_year_ticket\"), 2))\n",
    "    .filter(F.col(\"prev_year_trips\").isNotNull())\n",
    "    .orderBy(\"year\", \"service_type\")\n",
    ")\n",
    "save_result(qs, \"s_yoy_changes.csv\", \"Cambios YoY en volumen y ticket\", 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5759811",
   "metadata": {},
   "source": [
    "### t) Días con alta congestion_surcharge: efecto en total_amount vs días normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daily = (\n",
    "    df.filter(F.col(\"pickup_date\").isNotNull())\n",
    "    .groupBy(\"pickup_date\")\n",
    "    .agg(\n",
    "        F.avg(\"congestion_surcharge\").alias(\"avg_congestion\"),\n",
    "        F.avg(\"total_amount\").alias(\"avg_total\"),\n",
    "        F.count(\"*\").alias(\"trips\")\n",
    "    )\n",
    ")\n",
    "\n",
    "classified = (\n",
    "    daily.select(\n",
    "        F.when(F.col(\"avg_congestion\") > 2, \"High Congestion\").otherwise(\"Normal\").alias(\"day_type\"),\n",
    "        F.col(\"avg_congestion\"),\n",
    "        F.col(\"avg_total\"),\n",
    "        F.col(\"trips\")\n",
    "    )\n",
    ")\n",
    "\n",
    "qt = (\n",
    "    classified.groupBy(\"day_type\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"days\"),\n",
    "        F.round(F.avg(\"avg_congestion\"), 2).alias(\"avg_congestion_charge\"),\n",
    "        F.round(F.avg(\"avg_total\"), 2).alias(\"avg_total_amount\"),\n",
    "        F.round(F.avg(\"trips\"), 0).alias(\"avg_trips_per_day\")\n",
    "    )\n",
    "    .orderBy(\"day_type\")\n",
    ")\n",
    "save_result(qt, \"t_congestion_effect.csv\", \"Efecto de alta congestión vs días normales\", 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cabd7",
   "metadata": {},
   "source": [
    "## Resumen de Ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(EVID_DIR) if f.endswith('.csv')])\n",
    "\n",
    "\n",
    "print(f\"RUN_ID: {RUN_ID}\")\n",
    "print(f\" Evidencias en: {EVID_DIR}\")\n",
    "print(\"\\n📋 Archivos generados (muestra):\")\n",
    "for f in csv_files[:10]:\n",
    "    print(f\"   - {f}\")\n",
    "if len(csv_files) > 10:\n",
    "    print(f\"   ... y {len(csv_files) - 10} más\")\n",
    "\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
